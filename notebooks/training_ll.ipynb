{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "cKtZctcXJTAZ"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import sys\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m6kVWXZdvExC"
   },
   "outputs": [],
   "source": [
    "rm -rf {\"/content/ll_utils\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 118
    },
    "colab_type": "code",
    "id": "LNgr17uD0K--",
    "outputId": "37c2b9b8-ea8e-47bc-baf7-80feb9cf9c4c"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into 'll_utils'...\n",
      "remote: Enumerating objects: 35, done.\u001b[K\n",
      "remote: Counting objects:   2% (1/35)   \u001b[K\r",
      "remote: Counting objects:   5% (2/35)   \u001b[K\r",
      "remote: Counting objects:   8% (3/35)   \u001b[K\r",
      "remote: Counting objects:  11% (4/35)   \u001b[K\r",
      "remote: Counting objects:  14% (5/35)   \u001b[K\r",
      "remote: Counting objects:  17% (6/35)   \u001b[K\r",
      "remote: Counting objects:  20% (7/35)   \u001b[K\r",
      "remote: Counting objects:  22% (8/35)   \u001b[K\r",
      "remote: Counting objects:  25% (9/35)   \u001b[K\r",
      "remote: Counting objects:  28% (10/35)   \u001b[K\r",
      "remote: Counting objects:  31% (11/35)   \u001b[K\r",
      "remote: Counting objects:  34% (12/35)   \u001b[K\r",
      "remote: Counting objects:  37% (13/35)   \u001b[K\r",
      "remote: Counting objects:  40% (14/35)   \u001b[K\r",
      "remote: Counting objects:  42% (15/35)   \u001b[K\r",
      "remote: Counting objects:  45% (16/35)   \u001b[K\r",
      "remote: Counting objects:  48% (17/35)   \u001b[K\r",
      "remote: Counting objects:  51% (18/35)   \u001b[K\r",
      "remote: Counting objects:  54% (19/35)   \u001b[K\r",
      "remote: Counting objects:  57% (20/35)   \u001b[K\r",
      "remote: Counting objects:  60% (21/35)   \u001b[K\r",
      "remote: Counting objects:  62% (22/35)   \u001b[K\r",
      "remote: Counting objects:  65% (23/35)   \u001b[K\r",
      "remote: Counting objects:  68% (24/35)   \u001b[K\r",
      "remote: Counting objects:  71% (25/35)   \u001b[K\r",
      "remote: Counting objects:  74% (26/35)   \u001b[K\r",
      "remote: Counting objects:  77% (27/35)   \u001b[K\r",
      "remote: Counting objects:  80% (28/35)   \u001b[K\r",
      "remote: Counting objects:  82% (29/35)   \u001b[K\r",
      "remote: Counting objects:  85% (30/35)   \u001b[K\r",
      "remote: Counting objects:  88% (31/35)   \u001b[K\r",
      "remote: Counting objects:  91% (32/35)   \u001b[K\r",
      "remote: Counting objects:  94% (33/35)   \u001b[K\r",
      "remote: Counting objects:  97% (34/35)   \u001b[K\r",
      "remote: Counting objects: 100% (35/35)   \u001b[K\r",
      "remote: Counting objects: 100% (35/35), done.\n",
      "remote: Compressing objects:   3% (1/26)   \u001b[K\r",
      "remote: Compressing objects:   7% (2/26)   \u001b[K\r",
      "remote: Compressing objects:  11% (3/26)   \u001b[K\r",
      "remote: Compressing objects:  15% (4/26)   \u001b[K\r",
      "remote: Compressing objects:  19% (5/26)   \u001b[K\r",
      "remote: Compressing objects:  23% (6/26)   \u001b[K\r",
      "remote: Compressing objects:  26% (7/26)   \u001b[K\r",
      "remote: Compressing objects:  30% (8/26)   \u001b[K\r",
      "remote: Compressing objects:  34% (9/26)   \u001b[K\r",
      "remote: Compressing objects:  38% (10/26)   \u001b[K\r",
      "remote: Compressing objects:  42% (11/26)   \u001b[K\r",
      "remote: Compressing objects:  46% (12/26)   \u001b[K\r",
      "remote: Compressing objects:  50% (13/26)   \u001b[K\r",
      "remote: Compressing objects:  53% (14/26)   \u001b[K\r",
      "remote: Compressing objects:  57% (15/26)   \u001b[K\r",
      "remote: Compressing objects:  61% (16/26)   \u001b[K\r",
      "remote: Compressing objects:  65% (17/26)   \u001b[K\r",
      "remote: Compressing objects:  69% (18/26)   \u001b[K\r",
      "remote: Compressing objects:  73% (19/26)   \u001b[K\r",
      "remote: Compressing objects:  76% (20/26)   \u001b[K\r",
      "remote: Compressing objects:  80% (21/26)   \u001b[K\r",
      "remote: Compressing objects:  84% (22/26)   \u001b[K\r",
      "remote: Compressing objects:  88% (23/26)   \u001b[K\r",
      "remote: Compressing objects:  92% (24/26)   \u001b[K\r",
      "remote: Compressing objects:  96% (25/26)   \u001b[K\r",
      "remote: Compressing objects: 100% (26/26)   \u001b[K\r",
      "remote: Compressing objects: 100% (26/26), done.\u001b[K\n",
      "Unpacking objects:   2% (1/35)   \r",
      "Unpacking objects:   5% (2/35)   \r",
      "Unpacking objects:   8% (3/35)   \r",
      "Unpacking objects:  11% (4/35)   \r",
      "Unpacking objects:  14% (5/35)   \r",
      "Unpacking objects:  17% (6/35)   \r",
      "Unpacking objects:  20% (7/35)   \r",
      "Unpacking objects:  22% (8/35)   \r",
      "Unpacking objects:  25% (9/35)   \r",
      "Unpacking objects:  28% (10/35)   \r",
      "Unpacking objects:  31% (11/35)   \r",
      "Unpacking objects:  34% (12/35)   \r",
      "Unpacking objects:  37% (13/35)   \r",
      "Unpacking objects:  40% (14/35)   \r",
      "Unpacking objects:  42% (15/35)   \r",
      "Unpacking objects:  45% (16/35)   \r",
      "Unpacking objects:  48% (17/35)   \r",
      "Unpacking objects:  51% (18/35)   \r",
      "Unpacking objects:  54% (19/35)   \r",
      "Unpacking objects:  57% (20/35)   \r",
      "Unpacking objects:  60% (21/35)   \r",
      "Unpacking objects:  62% (22/35)   \r",
      "Unpacking objects:  65% (23/35)   \r",
      "Unpacking objects:  68% (24/35)   \r",
      "Unpacking objects:  71% (25/35)   \r",
      "Unpacking objects:  74% (26/35)   \r",
      "Unpacking objects:  77% (27/35)   \r",
      "remote: Total 35 (delta 7), reused 35 (delta 7), pack-reused 0\u001b[K\n",
      "Unpacking objects:  80% (28/35)   \r",
      "Unpacking objects:  82% (29/35)   \r",
      "Unpacking objects:  85% (30/35)   \r",
      "Unpacking objects:  88% (31/35)   \r",
      "Unpacking objects:  91% (32/35)   \r",
      "Unpacking objects:  94% (33/35)   \r",
      "Unpacking objects:  97% (34/35)   \r",
      "Unpacking objects: 100% (35/35)   \r",
      "Unpacking objects: 100% (35/35), done.\n"
     ]
    }
   ],
   "source": [
    "if 'google.colab' in sys.modules:\n",
    "    !git clone https://github.com/leighlin0511/ll_utils\n",
    "    sys.path.append('/content/ll_utils')\n",
    "    \n",
    "    from google.colab import auth\n",
    "    auth.authenticate_user()    \n",
    "\n",
    "import ll_cellular.main_ll as main_ll"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "rUq8HOwuvCKC"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HrPeVFofzIdy"
   },
   "source": [
    "## Train\n",
    "\n",
    "Set `MODEL_DIR` to be a Google Cloud Storage bucket that you can write to.   The code will write your checkpoins to this directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Z9MjRJpwJTAw",
    "outputId": "70567ac5-ec55-40eb-c4c5-5fc6ea724f04"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0711 06:55:56.734894 140059474896768 deprecation_wrapper.py:119] From /content/ll_utils/ll_cellular/main_ll.py:280: The name tf.logging.info is deprecated. Please use tf.compat.v1.logging.info instead.\n",
      "\n",
      "I0711 06:55:56.736506 140059474896768 main_ll.py:280] tpu: grpc://10.58.188.58:8470\n",
      "I0711 06:55:56.739896 140059474896768 main_ll.py:283] gcp_project: None\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<module 'll_cellular.main_ll' from '/content/ll_utils/ll_cellular/main_ll.py'>\n",
      "0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0711 06:55:57.858453 140059474896768 estimator.py:1984] Estimator's model_fn (functools.partial(<function resnet_model_fn at 0x7f61de551e18>, n_classes=1108, num_train_images=73030, data_format='channels_last', transpose_input=True, train_batch_size=512, iterations_per_loop=142, tf_precision='bfloat16', momentum=0.9, weight_decay=0.0001, base_learning_rate=0.2, warmup_epochs=5, model_dir='gs://kaggle-recursive-cell-image-storage/saved_model/1562302335/', use_tpu=True, resnet_depth=50)) includes params argument, but params are not passed to Estimator.\n",
      "I0711 06:55:57.861337 140059474896768 estimator.py:209] Using config: {'_model_dir': 'gs://kaggle-recursive-cell-image-storage/saved_model/1562302335/', '_tf_random_seed': None, '_save_summary_steps': 142, '_save_checkpoints_steps': 142, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "cluster_def {\n",
      "  job {\n",
      "    name: \"worker\"\n",
      "    tasks {\n",
      "      key: 0\n",
      "      value: \"10.58.188.58:8470\"\n",
      "    }\n",
      "  }\n",
      "}\n",
      "isolate_session_state: true\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': None, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_experimental_max_worker_delay_secs': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f61de64f320>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': 'grpc://10.58.188.58:8470', '_evaluation_master': 'grpc://10.58.188.58:8470', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1, '_tpu_config': TPUConfig(iterations_per_loop=142, num_shards=8, num_cores_per_replica=None, per_host_input_for_training=3, tpu_job_name=None, initial_infeed_sleep_secs=None, input_partition_dims=None, eval_training_input_configuration=2), '_cluster': <tensorflow.python.distribute.cluster_resolver.tpu_cluster_resolver.TPUClusterResolver object at 0x7f61ded2b9b0>}\n",
      "I0711 06:55:57.862656 140059474896768 tpu_context.py:209] _TPUContext: eval_on_tpu True\n",
      "I0711 06:55:57.864592 140059474896768 main_ll.py:338] Train glob: gs://rxrx1-us-central1/tfrecords/random-42/train/*.tfrecord\n",
      "I0711 06:55:57.866476 140059474896768 main_ll.py:351] Training for 142 steps (1.00 epochs in total). Current step 0.\n",
      "I0711 06:55:58.005954 140059474896768 tpu_system_metadata.py:78] Querying Tensorflow master (grpc://10.58.188.58:8470) for TPU system metadata.\n",
      "I0711 06:55:58.025109 140059474896768 tpu_system_metadata.py:148] Found TPU system:\n",
      "I0711 06:55:58.026524 140059474896768 tpu_system_metadata.py:149] *** Num TPU Cores: 8\n",
      "I0711 06:55:58.031559 140059474896768 tpu_system_metadata.py:150] *** Num TPU Workers: 1\n",
      "I0711 06:55:58.033653 140059474896768 tpu_system_metadata.py:152] *** Num TPU Cores Per Worker: 8\n",
      "I0711 06:55:58.035160 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:CPU:0, CPU, -1, 7047780406374528306)\n",
      "I0711 06:55:58.039710 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:0, TPU, 17179869184, 5122671363856471251)\n",
      "I0711 06:55:58.042120 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:1, TPU, 17179869184, 712035442304567635)\n",
      "I0711 06:55:58.043199 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:2, TPU, 17179869184, 4455287443631489220)\n",
      "I0711 06:55:58.045623 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:3, TPU, 17179869184, 9474265564678303369)\n",
      "I0711 06:55:58.046636 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:4, TPU, 17179869184, 15769860103389867102)\n",
      "I0711 06:55:58.049109 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:5, TPU, 17179869184, 12988495764992114597)\n",
      "I0711 06:55:58.050217 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:6, TPU, 17179869184, 18135399555602850200)\n",
      "I0711 06:55:58.052543 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU:7, TPU, 17179869184, 9148576979078449296)\n",
      "I0711 06:55:58.053593 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:TPU_SYSTEM:0, TPU_SYSTEM, 8589934592, 7106630783983635874)\n",
      "I0711 06:55:58.055934 140059474896768 tpu_system_metadata.py:154] *** Available Device: _DeviceAttributes(/job:worker/replica:0/task:0/device:XLA_CPU:0, XLA_CPU, 17179869184, 15506185792389874894)\n",
      "W0711 06:55:58.069324 140059474896768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/training_util.py:236: Variable.initialized_value (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use Variable.read_value. Variables in 2.X are initialized automatically both in eager and graph (inside tf.defun) contexts.\n",
      "I0711 06:55:58.096053 140059474896768 estimator.py:1145] Calling model_fn.\n",
      "W0711 06:55:58.125697 140059474896768 deprecation.py:323] From /content/ll_utils/ll_cellular/input.py:110: parallel_interleave (from tensorflow.contrib.data.python.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.parallel_interleave(...)`.\n",
      "W0711 06:55:58.127154 140059474896768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/interleave_ops.py:77: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
      "W0711 06:55:58.169739 140059474896768 deprecation.py:323] From /content/ll_utils/ll_cellular/input.py:122: map_and_batch (from tensorflow.contrib.data.python.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.experimental.map_and_batch(...)`.\n",
      "W0711 06:55:58.171163 140059474896768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/contrib/data/python/ops/batching.py:273: map_and_batch (from tensorflow.python.data.experimental.ops.batching) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.data.Dataset.map(map_func, num_parallel_calls)` followed by `tf.data.Dataset.batch(batch_size, drop_remainder)`. Static tf.data optimizations will take care of using the fused implementation.\n",
      "W0711 06:55:58.174565 140059474896768 deprecation_wrapper.py:119] From /content/ll_utils/ll_cellular/input.py:48: The name tf.FixedLenFeature is deprecated. Please use tf.io.FixedLenFeature instead.\n",
      "\n",
      "W0711 06:55:58.176647 140059474896768 deprecation_wrapper.py:119] From /content/ll_utils/ll_cellular/input.py:59: The name tf.parse_single_example is deprecated. Please use tf.io.parse_single_example instead.\n",
      "\n",
      "W0711 06:55:58.303410 140059474896768 deprecation.py:323] From /content/ll_utils/ll_cellular/official_resnet.py:211: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "W0711 06:55:58.575258 140059474896768 deprecation.py:323] From /content/ll_utils/ll_cellular/official_resnet.py:70: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.BatchNormalization instead.  In particular, `tf.control_dependencies(tf.GraphKeys.UPDATE_OPS)` should not be used (consult the `tf.keras.layers.batch_normalization` documentation).\n",
      "W0711 06:55:58.683456 140059474896768 deprecation.py:323] From /content/ll_utils/ll_cellular/official_resnet.py:413: max_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.MaxPooling2D instead.\n",
      "W0711 06:56:02.794529 140059474896768 deprecation.py:323] From /content/ll_utils/ll_cellular/official_resnet.py:442: average_pooling2d (from tensorflow.python.layers.pooling) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.AveragePooling2D instead.\n",
      "W0711 06:56:02.803335 140059474896768 deprecation.py:323] From /content/ll_utils/ll_cellular/official_resnet.py:449: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.dense instead.\n",
      "W0711 06:56:03.142937 140059474896768 deprecation_wrapper.py:119] From /content/ll_utils/ll_cellular/main_ll.py:125: The name tf.losses.softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.softmax_cross_entropy instead.\n",
      "\n",
      "W0711 06:56:03.241788 140059474896768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/losses/losses_impl.py:121: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0711 06:56:03.258131 140059474896768 deprecation_wrapper.py:119] From /content/ll_utils/ll_cellular/main_ll.py:131: The name tf.trainable_variables is deprecated. Please use tf.compat.v1.trainable_variables instead.\n",
      "\n",
      "W0711 06:56:03.362071 140059474896768 deprecation_wrapper.py:119] From /content/ll_utils/ll_cellular/main_ll.py:138: The name tf.train.get_global_step is deprecated. Please use tf.compat.v1.train.get_global_step instead.\n",
      "\n",
      "W0711 06:56:03.373323 140059474896768 deprecation_wrapper.py:119] From /content/ll_utils/ll_cellular/main_ll.py:145: The name tf.train.cosine_decay_restarts is deprecated. Please use tf.compat.v1.train.cosine_decay_restarts instead.\n",
      "\n",
      "W0711 06:56:03.420661 140059474896768 deprecation_wrapper.py:119] From /content/ll_utils/ll_cellular/main_ll.py:155: The name tf.train.MomentumOptimizer is deprecated. Please use tf.compat.v1.train.MomentumOptimizer instead.\n",
      "\n",
      "W0711 06:56:03.421997 140059474896768 deprecation_wrapper.py:119] From /content/ll_utils/ll_cellular/main_ll.py:167: The name tf.get_collection is deprecated. Please use tf.compat.v1.get_collection instead.\n",
      "\n",
      "W0711 06:56:03.423021 140059474896768 deprecation_wrapper.py:119] From /content/ll_utils/ll_cellular/main_ll.py:167: The name tf.GraphKeys is deprecated. Please use tf.compat.v1.GraphKeys instead.\n",
      "\n",
      "I0711 06:56:09.091975 140059474896768 basic_session_run_hooks.py:541] Create CheckpointSaverHook.\n",
      "I0711 06:56:09.645930 140059474896768 estimator.py:1147] Done calling model_fn.\n",
      "I0711 06:56:11.305015 140059474896768 tpu_estimator.py:499] TPU job name worker\n",
      "I0711 06:56:12.384322 140059474896768 monitored_session.py:240] Graph was finalized.\n",
      "I0711 06:56:15.668379 140059474896768 session_manager.py:500] Running local_init_op.\n",
      "I0711 06:56:16.048421 140059474896768 session_manager.py:502] Done running local_init_op.\n",
      "I0711 06:56:22.830510 140059474896768 basic_session_run_hooks.py:606] Saving checkpoints for 0 into gs://kaggle-recursive-cell-image-storage/saved_model/1562302335/model.ckpt.\n",
      "W0711 06:56:30.242686 140059474896768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow_estimator/python/estimator/tpu/tpu_estimator.py:741: Variable.load (from tensorflow.python.ops.variables) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Prefer Variable.assign which has equivalent behavior in 2.X.\n",
      "I0711 06:56:31.093925 140059474896768 util.py:98] Initialized dataset iterators in 0 seconds\n",
      "I0711 06:56:31.096142 140059474896768 session_support.py:332] Installing graceful shutdown hook.\n",
      "I0711 06:56:31.106456 140059474896768 session_support.py:82] Creating heartbeat manager for ['/job:worker/replica:0/task:0/device:CPU:0']\n",
      "I0711 06:56:31.110990 140059474896768 session_support.py:105] Configuring worker heartbeat: shutdown_mode: WAIT_FOR_COORDINATOR\n",
      "\n",
      "I0711 06:56:31.118324 140059474896768 tpu_estimator.py:557] Init TPU system\n",
      "I0711 06:56:38.651265 140059474896768 tpu_estimator.py:566] Initialized TPU in 7 seconds\n",
      "I0711 06:56:39.313946 140058137356032 tpu_estimator.py:514] Starting infeed thread controller.\n",
      "I0711 06:56:39.314736 140058128963328 tpu_estimator.py:533] Starting outfeed thread controller.\n",
      "I0711 06:56:39.725419 140059474896768 tpu_estimator.py:590] Enqueue next (142) batch(es) of data to infeed.\n",
      "I0711 06:56:39.727445 140059474896768 tpu_estimator.py:594] Dequeue next (142) batch(es) of data from outfeed.\n",
      "I0711 06:57:16.056915 140058128963328 tpu_estimator.py:275] Outfeed finished for iteration (0, 0)\n",
      "I0711 06:58:16.521049 140058128963328 tpu_estimator.py:275] Outfeed finished for iteration (0, 80)\n",
      "I0711 06:59:02.855900 140059474896768 basic_session_run_hooks.py:606] Saving checkpoints for 142 into gs://kaggle-recursive-cell-image-storage/saved_model/1562302335/model.ckpt.\n",
      "I0711 06:59:11.443002 140059474896768 basic_session_run_hooks.py:262] loss = 7.948485, step = 142\n",
      "I0711 06:59:11.867327 140059474896768 tpu_estimator.py:598] Stop infeed thread controller\n",
      "I0711 06:59:11.869107 140059474896768 tpu_estimator.py:430] Shutting down InfeedController thread.\n",
      "I0711 06:59:11.870305 140058137356032 tpu_estimator.py:425] InfeedController received shutdown signal, stopping.\n",
      "I0711 06:59:11.874059 140058137356032 tpu_estimator.py:530] Infeed thread finished, shutting down.\n",
      "I0711 06:59:11.879450 140059474896768 error_handling.py:96] infeed marked as finished\n",
      "I0711 06:59:11.882773 140059474896768 tpu_estimator.py:602] Stop output thread controller\n",
      "I0711 06:59:11.884650 140059474896768 tpu_estimator.py:430] Shutting down OutfeedController thread.\n",
      "I0711 06:59:11.886157 140058128963328 tpu_estimator.py:425] OutfeedController received shutdown signal, stopping.\n",
      "I0711 06:59:11.888241 140058128963328 tpu_estimator.py:541] Outfeed thread finished, shutting down.\n",
      "I0711 06:59:11.890155 140059474896768 error_handling.py:96] outfeed marked as finished\n",
      "I0711 06:59:11.891844 140059474896768 tpu_estimator.py:606] Shutdown TPU system.\n",
      "I0711 06:59:18.656209 140059474896768 estimator.py:368] Loss for final step: 7.948485.\n",
      "I0711 06:59:18.658655 140059474896768 error_handling.py:96] training_loop marked as finished\n",
      "I0711 06:59:18.659939 140059474896768 main_ll.py:358] Finished training up to step 142. Elapsed seconds 200.\n",
      "I0711 06:59:18.660944 140059474896768 main_ll.py:363] Finished training up to step 142. Elapsed seconds 200.\n",
      "I0711 06:59:18.662493 140059474896768 main_ll.py:365] Exporting SavedModel.\n",
      "I0711 06:59:20.036218 140059474896768 estimator.py:1145] Calling model_fn.\n",
      "I0711 06:59:20.037936 140059474896768 tpu_estimator.py:2965] Running infer on CPU\n",
      "I0711 06:59:22.706096 140059474896768 estimator.py:1147] Done calling model_fn.\n",
      "W0711 06:59:22.707335 140059474896768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/saved_model/signature_def_utils_impl.py:201: build_tensor_info (from tensorflow.python.saved_model.utils_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.utils.build_tensor_info or tf.compat.v1.saved_model.build_tensor_info.\n",
      "I0711 06:59:22.708822 140059474896768 export_utils.py:170] Signatures INCLUDED in export for Classify: None\n",
      "I0711 06:59:22.709574 140059474896768 export_utils.py:170] Signatures INCLUDED in export for Regress: None\n",
      "I0711 06:59:22.710400 140059474896768 export_utils.py:170] Signatures INCLUDED in export for Predict: ['classify', 'serving_default']\n",
      "I0711 06:59:22.711277 140059474896768 export_utils.py:170] Signatures INCLUDED in export for Train: None\n",
      "I0711 06:59:22.712239 140059474896768 export_utils.py:170] Signatures INCLUDED in export for Eval: None\n",
      "W0711 06:59:23.009348 140059474896768 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/saver.py:1276: checkpoint_exists (from tensorflow.python.training.checkpoint_management) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use standard file APIs to check for files with this prefix.\n",
      "I0711 06:59:23.103283 140059474896768 saver.py:1280] Restoring parameters from gs://kaggle-recursive-cell-image-storage/saved_model/1562302335/model.ckpt-142\n",
      "I0711 06:59:27.677591 140059474896768 builder_impl.py:661] Assets added to graph.\n",
      "I0711 06:59:27.678916 140059474896768 builder_impl.py:456] No assets to write.\n",
      "I0711 06:59:32.917248 140059474896768 builder_impl.py:421] SavedModel written to: gs://kaggle-recursive-cell-image-storage/saved_model/1562302335/saved_model/temp-b'1562828358'/saved_model.pb\n"
     ]
    }
   ],
   "source": [
    "MODEL_DIR = 'gs://kaggle-recursive-cell-image-storage/saved_model/1562302335/'\n",
    "URL_BASE_PATH = 'gs://rxrx1-us-central1/tfrecords/random-42'\n",
    "\n",
    "# make sure we're in a TPU runtime\n",
    "assert 'COLAB_TPU_ADDR' in os.environ\n",
    "\n",
    "# set TPU-relevant args\n",
    "tpu_grpc = 'grpc://{}'.format(os.environ['COLAB_TPU_ADDR'])\n",
    "num_shards = 8  # colab uses Cloud TPU v2-8\n",
    "\n",
    "# upload credentials to the TPU\n",
    "with tf.Session(tpu_grpc) as sess:\n",
    "    data = json.load(open('/content/adc.json'))\n",
    "    tf.contrib.cloud.configure_gcs(sess, credentials=data)\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "#print(main_ll)\n",
    "from tensorflow.python.estimator import estimator\n",
    "\n",
    "current_step = estimator._load_global_step_from_checkpoint_dir(MODEL_DIR)\n",
    "print(current_step)\n",
    "\n",
    "main_ll.main(use_tpu=True,\n",
    "     tpu=tpu_grpc,\n",
    "     gcp_project=None,\n",
    "     tpu_zone=None,\n",
    "     url_base_path=URL_BASE_PATH,\n",
    "     use_cache=False,\n",
    "     model_dir=MODEL_DIR,\n",
    "     train_epochs=1,\n",
    "     train_batch_size=512,\n",
    "     num_train_images=73030,\n",
    "     epochs_per_loop=1,\n",
    "     log_step_count_epochs=1,\n",
    "     num_cores=num_shards,\n",
    "     data_format='channels_last',\n",
    "     transpose_input=True,\n",
    "     tf_precision='bfloat16',\n",
    "     n_classes=1108,\n",
    "     momentum=0.9,\n",
    "     weight_decay=1e-4,\n",
    "     base_learning_rate=0.2,\n",
    "     warmup_epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HRaWwwjwenNq"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "training_ll.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
